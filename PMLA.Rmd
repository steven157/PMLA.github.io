---
title: "Practical Machine Learning Assignment"
author: "steven157"
date: "Monday, May 25, 2015"
output: html_document
---

# Project Description
- We were given 6 participants' data from accelerometers on the belt, forearm, arm, and dumbell by performing barbell lifts correctly and incorrectly in 5 different ways.
- Based on these data, we are going to predict the manner in which they did the exercise. <br>

# Activate required packages.
```{r, message = F, cache = T}
library(abind)
library(arm)
library(caret)
library(caTools)
library(kernlab)
library(klaR)
library(nnet)
library(rattle)
library(randomForest)
library(rpart)
```

Set a seed for pseudo-random generator.
```{r, cache = T}
set.seed(777)
```

#Read data from working directory
```{r, cache = T}
train <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
test <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
```

#Process of cleaning and pre-processing traning dataset
- Check names' coherence.
```{r, cache = T}
all.equal(colnames(test)[1:length(colnames(test))-1], colnames(train)[1:length(colnames(train))-1])
```
- Clean out variables with high proportion of NAs and low variance.
- Specifically, variables with NAs more than half or related with data acquisition were removed.
- For easier computation with low informativity loss.
```{r, cache = T}
nearzero <- nearZeroVar(train, saveMetrics = TRUE)
train <- train[, !nearzero$nzv]
toberem <- sapply(colnames(train), function(x) if(sum(is.na(train[, x])) > 0.50*nrow(train)) {return(TRUE)} else{return(FALSE)})
train <- train[, !toberem]
train <- train[, -(1:6)]
```
- Correlation analysis showed that majority of the variables are highly orrelated.
- Hence, PCA was used for the pre-processing process.
- The variables selected for model specification is presented below.
```{r, cache = T}
HC <- caret::findCorrelation(cor(train[, -53]), cutoff=0.8)
names(train)[HC]
names(train)
```

# Cross Validation
- TrainControl is used to perform 7-fold cross validation.
- Reduce out of sample error and avoid overfitting
```{r, cache = T}
tc <- trainControl(method = "cv", number = 7, verboseIter=FALSE , preProcOptions="pca", allowParallel=TRUE)
```

# Model Specification
- Bayes Generalized Linear model.
```{r, cache = T, results = "hide", message = F, warning = F}
BGLM <- train(classe ~ ., data = train, method = "bayesglm", trControl= tc)
```
- Logit Boosted model.
```{r, cache = T, results = "hide", message = F, warning = F}
LB <- train(classe ~ ., data = train, method = "LogitBoost", trControl= tc)
```
- Neural Net.
```{r, cache = T, results = "hide", message = F, warning = F}
NN <- train(classe ~ ., data = train, method = "nnet", trControl= tc, verbose=FALSE)
```
- Random Forest.
```{r, cache = T, results = "hide", message = F, warning = F}
RF <- train(classe ~ ., data = train, method = "rf", trControl= tc)
```
- Support Vector Machine (linear)
```{r, cache = T, results = "hide", message = F, warning = F}
SVML <- train(classe ~ ., data = train, method = "svmLinear", trControl= tc)
```
- Support Vector Machine (radial)
```{r, cache = T, results = "hide", message = F, warning = F}
SVMR <- train(classe ~ ., data = train, method = "svmRadial", trControl= tc)
```
<br>
- Accuracy comparison among these models.
```{r, cache = T}
model <- c("Bayes GLM", "LogitBoost", "Neural Net", "Random Forest", "SVM (linear)", "SVM (radial)")
ACC <- c(max(BGLM$results$Accuracy), max(LB$results$Accuracy),
        max(NN$results$Accuracy), max(RF$results$Accuracy),
        max(SVML$results$Accuracy), max(SVMR$results$Accuracy))        
KPP <- c(max(BGLM$results$Kappa), max(LB$results$Kappa),
        max(NN$results$Kappa), max(RF$results$Kappa),
        max(SVML$results$Kappa), max(SVMR$results$Kappa))  
performance <- cbind(model,ACC,KPP)
knitr::kable(performance)
```

- Based on the above table, Random Forest & Support Vector Machine (radial) provide the most accurate results and will be used for prediction on testing dataset.<br>

#Prediction on testing dataset
- Predict class variables on testing dataset
- Compare prediction similarity from both models
```{r, cache = T}
RFP <- predict(RF, test)
SVMRP <- predict(SVMR, test)
prediction <- data.frame(cbind(RFP, SVMRP))
prediction$match <- with(prediction, RFP == SVMRP)
colnames(prediction) <- c("Random Forest", "SVM (radial)", "Prediction Match?")
knitr::kable(prediction)
```

- THe prediction result is generated by the code below for each test case
```{r, eval = F, cache = T}
pml_write_files = function(x){
        n = length(x)
        for(i in 1:n){
                filename = paste0("problem_id_",i,".txt")
                write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
        }
}
pml_write_files(RFP)
pml_write_files(SVMRP)
```